{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d00134",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flickrapi\n",
    "import os\n",
    "import urllib.request\n",
    "import sys\n",
    "import re\n",
    "import zipfile\n",
    "import stat\n",
    "import time\n",
    "import requests\n",
    "import io\n",
    "from pathlib import Path\n",
    "from jmd_imagescraper.core import *\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import WebDriverException, SessionNotCreatedException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from sys import platform\n",
    "from urllib.parse import urlparse\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2f66be",
   "metadata": {},
   "source": [
    "# Main variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6905c2d4",
   "metadata": {},
   "source": [
    "### Flickr API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64760ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr_api = 'YOUR_API_KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f964aad",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10948af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['cat', 'boy', 'awesome image']\n",
    "out_path = './out'\n",
    "max_num = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21c60be",
   "metadata": {},
   "source": [
    "# Flickr Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1709c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flickr_parse(flickr_api, query, max_num, out_path):\n",
    "    query_out_path = out_path + f'/{query}'\n",
    "    if not os.path.isdir(query_out_path):\n",
    "        os.mkdir(query_out_path)\n",
    "    flickr_api = flickr_api.split(':')\n",
    "    try:\n",
    "        flickr = flickrapi.FlickrAPI(flickr_api[0], flickr_api[1], cache=True)\n",
    "    except:\n",
    "        print('Your API key is invalid')\n",
    "        exit()\n",
    "    try:\n",
    "        photos = flickr.walk(text=query, tag_mode='all', tags=query, extras='url_c', per_page=1, sort='relevance')\n",
    "        counter = 0\n",
    "        for photo in photos:\n",
    "            try:\n",
    "                url = photo.get('url_c')\n",
    "                urllib.request.urlretrieve(url, f'{query_out_path}/{counter}.jpg')\n",
    "                counter += 1\n",
    "            except:\n",
    "                pass\n",
    "            if counter > max_num - 1:\n",
    "                break\n",
    "        print(f'{counter} Images downloaded from Flickr to {query_out_path}')\n",
    "    except:\n",
    "        print(f'Cannot parse {query} from Flickr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c85fd0",
   "metadata": {},
   "source": [
    "# DuckDuckGo Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98efa913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duckduckgo_parser(query, max_num, out_path):\n",
    "    duckduckgo_search(out_path, query, query, max_results=max_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f684a477",
   "metadata": {},
   "source": [
    "# Google Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df5289f",
   "metadata": {},
   "source": [
    "### Scary things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c503c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_lastest_chromedriver(current_chrome_version=\"\"):\n",
    "    def get_platform_filename():\n",
    "        filename = ''\n",
    "        is_64bits = sys.maxsize > 2**32\n",
    "        if platform == \"linux\" or platform == \"linux2\":\n",
    "            filename += 'linux'\n",
    "            filename += '64' if is_64bits else '32'\n",
    "        elif platform == \"darwin\":\n",
    "            filename += 'mac64'\n",
    "        elif platform == \"win32\":\n",
    "            filename += 'win32'\n",
    "        filename += '.zip'\n",
    "        return filename\n",
    "    \n",
    "    result = False\n",
    "    \n",
    "    try:\n",
    "        url = 'https://chromedriver.chromium.org/downloads'\n",
    "        base_driver_url = 'https://chromedriver.storage.googleapis.com/'\n",
    "        file_name = 'chromedriver_' + get_platform_filename()\n",
    "        pattern = 'https://.*?path=(\\d+\\.\\d+\\.\\d+\\.\\d+)'\n",
    "        stream = urllib.request.urlopen(url)\n",
    "        content = stream.read().decode('utf8')\n",
    "        all_match = re.findall(pattern, content)\n",
    "        if all_match:\n",
    "            if(current_chrome_version!=\"\"):\n",
    "                print(\"[INFO] updating chromedriver\")\n",
    "                all_match = list(set(re.findall(pattern, content)))\n",
    "                current_chrome_version = \".\".join(current_chrome_version.split(\".\")[:-1])\n",
    "                version_match = [i for i in all_match if re.search(\"^%s\"%current_chrome_version,i)]\n",
    "                version = version_match[0]\n",
    "            else:\n",
    "                print(\"[INFO] installing new chromedriver\")\n",
    "                version = all_match[1]\n",
    "            driver_url = base_driver_url + version + '/' + file_name\n",
    "            print('[INFO] downloading chromedriver ver: %s: %s'% (version, driver_url))\n",
    "            app_path = os.path.dirname(os.path.realpath(__file__))\n",
    "            \n",
    "            chromedriver_path = os.path.normpath('C:/Software/Programming/chromedriver/chromedriver.exe')\n",
    "            \n",
    "            file_path = os.path.normpath(os.path.join(app_path, 'webdriver', file_name))\n",
    "            urllib.request.urlretrieve(driver_url, file_path)\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(os.path.normpath(os.path.join(app_path, 'webdriver')))\n",
    "            st = os.stat(chromedriver_path)\n",
    "            os.chmod(chromedriver_path, st.st_mode | stat.S_IEXEC)\n",
    "            print('[INFO] lastest chromedriver downloaded')\n",
    "            os.remove(file_path)\n",
    "            result = True\n",
    "    \n",
    "    except Exception:\n",
    "        print(\"[WARN] unable to download lastest chromedriver. the system will use the local version instead.\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5bc695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleImageScraper():\n",
    "    def __init__(self, webdriver_path, image_path, search_key=\"image\", number_of_images=1, headless=True, min_resolution=(0, 0), max_resolution=(1920, 1080), max_missed=10):\n",
    "        image_path = os.path.join(image_path, search_key)\n",
    "        if (type(number_of_images)!=int):\n",
    "            print(\"[Error] Number of images must be integer value.\")\n",
    "            return\n",
    "        if not os.path.exists(image_path):\n",
    "            print(\"[INFO] Image path not found. Creating a new folder.\")\n",
    "            os.makedirs(image_path)\n",
    "        while(True):\n",
    "            options = Options()\n",
    "            if(headless):\n",
    "                options.add_argument('--headless')\n",
    "            driver = webdriver.Chrome(webdriver_path, chrome_options=options)\n",
    "            driver.set_window_size(1400,1050)\n",
    "            driver.get(\"https://www.google.com\")\n",
    "            if driver.find_elements_by_id(\"L2AGLb\"):\n",
    "                driver.find_element_by_id(\"L2AGLb\").click()\n",
    "            break\n",
    "        self.driver = driver\n",
    "        self.search_key = search_key\n",
    "        self.number_of_images = number_of_images\n",
    "        self.webdriver_path = webdriver_path\n",
    "        self.image_path = image_path\n",
    "        self.url = \"https://www.google.com/search?q=%s&source=lnms&tbm=isch&sa=X&ved=2ahUKEwie44_AnqLpAhUhBWMBHUFGD90Q_AUoAXoECBUQAw&biw=1920&bih=947\"%(search_key)\n",
    "        self.headless=headless\n",
    "        self.min_resolution = min_resolution\n",
    "        self.max_resolution = max_resolution\n",
    "        self.max_missed = max_missed\n",
    "\n",
    "    def find_image_urls(self):\n",
    "        print(\"[INFO] Gathering image links\")\n",
    "        image_urls=[]\n",
    "        count = 0\n",
    "        missed_count = 0\n",
    "        self.driver.get(self.url)\n",
    "        time.sleep(3)\n",
    "        indx = 1\n",
    "        while self.number_of_images > count:\n",
    "            try:\n",
    "                imgurl = self.driver.find_element_by_xpath('//*[@id=\"islrg\"]/div[1]/div[%s]/a[1]/div[1]/img'%(str(indx)))\n",
    "                imgurl.click()\n",
    "                missed_count = 0\n",
    "            except Exception:\n",
    "                missed_count = missed_count + 1\n",
    "                if (missed_count>self.max_missed):\n",
    "                    print(\"[INFO] Maximum missed photos reached, exiting...\")\n",
    "                    break\n",
    "\n",
    "            try:\n",
    "                time.sleep(1)\n",
    "                class_names = [\"n3VNCb\"]\n",
    "                images = [self.driver.find_elements_by_class_name(class_name) for class_name in class_names if len(self.driver.find_elements_by_class_name(class_name)) != 0 ][0]\n",
    "                for image in images:\n",
    "                    src_link = image.get_attribute(\"src\")\n",
    "                    if((\"http\" in  src_link) and (not \"encrypted\" in src_link)):\n",
    "                        print(\n",
    "                            f\"[INFO] {self.search_key} \\t #{count} \\t {src_link}\")\n",
    "                        image_urls.append(src_link)\n",
    "                        count +=1\n",
    "                        break\n",
    "            except Exception:\n",
    "                print(\"[INFO] Unable to get link\")\n",
    "\n",
    "            try:\n",
    "                if(count%3==0):\n",
    "                    self.driver.execute_script(\"window.scrollTo(0, \"+str(indx*60)+\");\")\n",
    "                element = self.driver.find_element_by_class_name(\"mye4qd\")\n",
    "                element.click()\n",
    "                print(\"[INFO] Loading next page\")\n",
    "                time.sleep(3)\n",
    "            except Exception:\n",
    "                time.sleep(1)\n",
    "            indx += 1\n",
    "\n",
    "\n",
    "        self.driver.quit()\n",
    "        print(\"[INFO] Google search ended\")\n",
    "        return image_urls\n",
    "\n",
    "    def save_images(self,image_urls, keep_filenames=True):\n",
    "        print(keep_filenames)\n",
    "        print(\"[INFO] Saving image, please wait...\")\n",
    "        for indx,image_url in enumerate(image_urls):\n",
    "            try:\n",
    "                print(\"[INFO] Image url:%s\"%(image_url))\n",
    "                search_string = ''.join(e for e in self.search_key if e.isalnum())\n",
    "                image = requests.get(image_url,timeout=5)\n",
    "                if image.status_code == 200:\n",
    "                    with Image.open(io.BytesIO(image.content)) as image_from_web:\n",
    "                        try:\n",
    "                            if (keep_filenames):\n",
    "                                o = urlparse(image_url)\n",
    "                                image_url = o.scheme + \"://\" + o.netloc + o.path\n",
    "                                name = os.path.splitext(os.path.basename(image_url))[0]\n",
    "                                filename = \"%s.%s\"%(name,image_from_web.format.lower())\n",
    "                            else:\n",
    "                                filename = \"%s%s.%s\"%(search_string,str(indx),image_from_web.format.lower())\n",
    "\n",
    "                            image_path = os.path.join(self.image_path, filename)\n",
    "                            print(\n",
    "                                f\"[INFO] {self.search_key} \\t {indx} \\t Image saved at: {image_path}\")\n",
    "                            image_from_web.save(image_path)\n",
    "                        except OSError:\n",
    "                            rgb_im = image_from_web.convert('RGB')\n",
    "                            rgb_im.save(image_path)\n",
    "                        image_resolution = image_from_web.size\n",
    "                        if image_resolution != None:\n",
    "                            if image_resolution[0]<self.min_resolution[0] or image_resolution[1]<self.min_resolution[1] or image_resolution[0]>self.max_resolution[0] or image_resolution[1]>self.max_resolution[1]:\n",
    "                                image_from_web.close()\n",
    "                                os.remove(image_path)\n",
    "\n",
    "                        image_from_web.close()\n",
    "            except Exception as e:\n",
    "                print(\"[ERROR] Download failed: \",e)\n",
    "                pass\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(\"[INFO] Downloads completed. Please note that some photos were not downloaded as they were not in the correct format (e.g. jpg, jpeg, png)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b675b1",
   "metadata": {},
   "source": [
    "### Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_parser(query, max_num, out_path):\n",
    "    if not os.path.isdir(out_path):\n",
    "        os.mkdir(out_path)\n",
    "    \n",
    "    webdriver_path = os.path.normpath('PATH_TO_chromedriver.exe')\n",
    "    \n",
    "    image_scraper = GoogleImageScraper(\n",
    "        webdriver_path, out_path, query, max_num, True, (0, 0), (9999, 9999))\n",
    "    image_urls = image_scraper.find_image_urls()\n",
    "    image_scraper.save_images(image_urls)\n",
    "    del image_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a16328",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    flickr_parse(flickr_api, query, max_num, out_path)\n",
    "    duckduckgo_parser(query, max_num, out_path)\n",
    "    google_parser(query, max_num, out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
